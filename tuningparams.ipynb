{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ppscore as pps\n",
    "import statsmodels as sm\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, random_forest, gaussian_nb, gradient_boosting, multinomial_nb\n",
    "from hyperopt import tpe\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtype_L0</th>\n",
       "      <th>Num_houses</th>\n",
       "      <th>Avg_hh_size</th>\n",
       "      <th>age_L1</th>\n",
       "      <th>maintype_L2</th>\n",
       "      <th>romcath_L3</th>\n",
       "      <th>Protestant</th>\n",
       "      <th>O_religion</th>\n",
       "      <th>N_religion</th>\n",
       "      <th>Married</th>\n",
       "      <th>Living_together</th>\n",
       "      <th>O_relation</th>\n",
       "      <th>Singles</th>\n",
       "      <th>hh_wo_child</th>\n",
       "      <th>hh_w_child</th>\n",
       "      <th>H_lvl_edu</th>\n",
       "      <th>M_lvl_edu</th>\n",
       "      <th>L_lvl_edu</th>\n",
       "      <th>H_status</th>\n",
       "      <th>Entrepreneur</th>\n",
       "      <th>Farmer</th>\n",
       "      <th>Mid_management</th>\n",
       "      <th>Skld_labor</th>\n",
       "      <th>Unskld_labor</th>\n",
       "      <th>Soc_cls_A</th>\n",
       "      <th>Soc_cls_B1</th>\n",
       "      <th>Soc_cls_B2</th>\n",
       "      <th>Soc_cls_C</th>\n",
       "      <th>Soc_cls_D</th>\n",
       "      <th>R_house</th>\n",
       "      <th>O_house</th>\n",
       "      <th>1_car</th>\n",
       "      <th>2_cars</th>\n",
       "      <th>N_car</th>\n",
       "      <th>Nat_Hlth_Serv</th>\n",
       "      <th>Prv_Hlth_Insur</th>\n",
       "      <th>Inc_u_30k</th>\n",
       "      <th>Inc_btw_30_45k</th>\n",
       "      <th>Inc_btw_45_75k</th>\n",
       "      <th>Inc_75_122k</th>\n",
       "      <th>Inc_ovr_123k</th>\n",
       "      <th>Avg_inc</th>\n",
       "      <th>PP_cls</th>\n",
       "      <th>Contri_prv_3p_insur</th>\n",
       "      <th>Firm_Contri_3p_ insur</th>\n",
       "      <th>Ag_Contri_3p_insur</th>\n",
       "      <th>Contri_car_pol</th>\n",
       "      <th>Contri_deliv_van_pol</th>\n",
       "      <th>Contri_motorcycle/scooter_pol</th>\n",
       "      <th>Contri_lorry_pol</th>\n",
       "      <th>Contri_trailer_pols</th>\n",
       "      <th>Contri_tractor_pol</th>\n",
       "      <th>Contri_ag_machine_pol</th>\n",
       "      <th>Contri_moped_pol</th>\n",
       "      <th>Contri_life_insur</th>\n",
       "      <th>Contri_prv_accid_insur_pol</th>\n",
       "      <th>Contri_fam_accid_insur_pol</th>\n",
       "      <th>Contri_disabl_insur_pol</th>\n",
       "      <th>Contri_fire_pol</th>\n",
       "      <th>Contri_surfb_pol</th>\n",
       "      <th>Contri_boat_pol</th>\n",
       "      <th>Contri_bike_pol</th>\n",
       "      <th>Contri_prop_insur_pol</th>\n",
       "      <th>Contri_ss_insur_polo</th>\n",
       "      <th>Num_prv_3p_insur</th>\n",
       "      <th>Num_firm_3p_insur</th>\n",
       "      <th>Num_ag_3p_insur</th>\n",
       "      <th>Num_car_pol</th>\n",
       "      <th>Num_deliv_van_pol</th>\n",
       "      <th>Num_motorcycle/scooter_pol</th>\n",
       "      <th>Num_lorry_pol</th>\n",
       "      <th>Num_trailer_pol</th>\n",
       "      <th>Num_tractor_pol</th>\n",
       "      <th>Num_ag_machines_pol</th>\n",
       "      <th>Num_moped_pol</th>\n",
       "      <th>Num_life_insur_pol</th>\n",
       "      <th>Num_prv_accid_insur_pol</th>\n",
       "      <th>Num_fam_ccid_insur_pol</th>\n",
       "      <th>Num_disabl_insur_pol</th>\n",
       "      <th>Num_fire_pol</th>\n",
       "      <th>Num_surfb_pol</th>\n",
       "      <th>Num_boat_pol</th>\n",
       "      <th>Num_bike_pol</th>\n",
       "      <th>Num_prop_insur_pol</th>\n",
       "      <th>num_ss_insur_pol</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.00000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.00000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "      <td>9822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.253207</td>\n",
       "      <td>1.108735</td>\n",
       "      <td>2.677561</td>\n",
       "      <td>2.996437</td>\n",
       "      <td>5.779067</td>\n",
       "      <td>0.700672</td>\n",
       "      <td>4.637650</td>\n",
       "      <td>1.050092</td>\n",
       "      <td>3.262981</td>\n",
       "      <td>6.188964</td>\n",
       "      <td>0.873142</td>\n",
       "      <td>2.286602</td>\n",
       "      <td>1.887294</td>\n",
       "      <td>3.237324</td>\n",
       "      <td>4.302891</td>\n",
       "      <td>1.484525</td>\n",
       "      <td>3.307269</td>\n",
       "      <td>4.592038</td>\n",
       "      <td>1.898799</td>\n",
       "      <td>0.403278</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>2.877113</td>\n",
       "      <td>2.226532</td>\n",
       "      <td>2.291183</td>\n",
       "      <td>1.650682</td>\n",
       "      <td>1.595093</td>\n",
       "      <td>2.204744</td>\n",
       "      <td>3.742211</td>\n",
       "      <td>1.068214</td>\n",
       "      <td>4.187742</td>\n",
       "      <td>4.819487</td>\n",
       "      <td>6.022501</td>\n",
       "      <td>1.335980</td>\n",
       "      <td>1.956730</td>\n",
       "      <td>6.254327</td>\n",
       "      <td>2.750662</td>\n",
       "      <td>2.577072</td>\n",
       "      <td>3.505498</td>\n",
       "      <td>2.739462</td>\n",
       "      <td>0.808491</td>\n",
       "      <td>0.208002</td>\n",
       "      <td>3.80452</td>\n",
       "      <td>4.260334</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>0.038892</td>\n",
       "      <td>0.073712</td>\n",
       "      <td>2.956424</td>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.170841</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>0.019344</td>\n",
       "      <td>0.093565</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.215027</td>\n",
       "      <td>0.202301</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.018733</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>1.849420</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.015272</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>0.016697</td>\n",
       "      <td>0.045408</td>\n",
       "      <td>0.400020</td>\n",
       "      <td>0.014050</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.557218</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>0.040216</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>0.034413</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.071065</td>\n",
       "      <td>0.079821</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.574018</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.03146</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.059662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.918058</td>\n",
       "      <td>0.412101</td>\n",
       "      <td>0.780701</td>\n",
       "      <td>0.804660</td>\n",
       "      <td>2.874148</td>\n",
       "      <td>1.015107</td>\n",
       "      <td>1.721212</td>\n",
       "      <td>1.011156</td>\n",
       "      <td>1.606287</td>\n",
       "      <td>1.896070</td>\n",
       "      <td>0.961955</td>\n",
       "      <td>1.710674</td>\n",
       "      <td>1.779238</td>\n",
       "      <td>1.609139</td>\n",
       "      <td>1.984152</td>\n",
       "      <td>1.645968</td>\n",
       "      <td>1.723377</td>\n",
       "      <td>2.279839</td>\n",
       "      <td>1.814406</td>\n",
       "      <td>0.786792</td>\n",
       "      <td>1.106349</td>\n",
       "      <td>1.846703</td>\n",
       "      <td>1.748025</td>\n",
       "      <td>1.684008</td>\n",
       "      <td>1.742410</td>\n",
       "      <td>1.321487</td>\n",
       "      <td>1.534163</td>\n",
       "      <td>1.944900</td>\n",
       "      <td>1.298229</td>\n",
       "      <td>3.093127</td>\n",
       "      <td>3.093541</td>\n",
       "      <td>1.543980</td>\n",
       "      <td>1.213627</td>\n",
       "      <td>1.596842</td>\n",
       "      <td>2.000374</td>\n",
       "      <td>2.002960</td>\n",
       "      <td>2.073125</td>\n",
       "      <td>1.871365</td>\n",
       "      <td>1.950625</td>\n",
       "      <td>1.173771</td>\n",
       "      <td>0.561832</td>\n",
       "      <td>1.33093</td>\n",
       "      <td>1.998913</td>\n",
       "      <td>0.956555</td>\n",
       "      <td>0.356924</td>\n",
       "      <td>0.507818</td>\n",
       "      <td>2.921736</td>\n",
       "      <td>0.566108</td>\n",
       "      <td>0.888518</td>\n",
       "      <td>0.237556</td>\n",
       "      <td>0.200885</td>\n",
       "      <td>0.604350</td>\n",
       "      <td>0.215408</td>\n",
       "      <td>0.810899</td>\n",
       "      <td>0.910574</td>\n",
       "      <td>0.188699</td>\n",
       "      <td>0.213712</td>\n",
       "      <td>0.375350</td>\n",
       "      <td>1.881271</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>0.244210</td>\n",
       "      <td>0.157198</td>\n",
       "      <td>0.211487</td>\n",
       "      <td>0.396983</td>\n",
       "      <td>0.492001</td>\n",
       "      <td>0.126058</td>\n",
       "      <td>0.144319</td>\n",
       "      <td>0.608575</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>0.223622</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>0.116251</td>\n",
       "      <td>0.249706</td>\n",
       "      <td>0.109954</td>\n",
       "      <td>0.267432</td>\n",
       "      <td>0.384431</td>\n",
       "      <td>0.067535</td>\n",
       "      <td>0.088764</td>\n",
       "      <td>0.071224</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>0.20907</td>\n",
       "      <td>0.092647</td>\n",
       "      <td>0.117728</td>\n",
       "      <td>0.236872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subtype_L0   Num_houses  Avg_hh_size       age_L1  maintype_L2  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean     24.253207     1.108735     2.677561     2.996437     5.779067   \n",
       "std      12.918058     0.412101     0.780701     0.804660     2.874148   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
       "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
       "max      41.000000    10.000000     6.000000     6.000000    10.000000   \n",
       "\n",
       "        romcath_L3   Protestant   O_religion   N_religion      Married  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      0.700672     4.637650     1.050092     3.262981     6.188964   \n",
       "std       1.015107     1.721212     1.011156     1.606287     1.896070   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     4.000000     0.000000     2.000000     5.000000   \n",
       "50%       0.000000     5.000000     1.000000     3.000000     6.000000   \n",
       "75%       1.000000     6.000000     2.000000     4.000000     7.000000   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000   \n",
       "\n",
       "       Living_together   O_relation      Singles  hh_wo_child   hh_w_child  \\\n",
       "count      9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean          0.873142     2.286602     1.887294     3.237324     4.302891   \n",
       "std           0.961955     1.710674     1.779238     1.609139     1.984152   \n",
       "min           0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%           0.000000     1.000000     0.000000     2.000000     3.000000   \n",
       "50%           1.000000     2.000000     2.000000     3.000000     4.000000   \n",
       "75%           1.000000     3.000000     3.000000     4.000000     6.000000   \n",
       "max           7.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "         H_lvl_edu    M_lvl_edu    L_lvl_edu     H_status  Entrepreneur  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000   9822.000000   \n",
       "mean      1.484525     3.307269     4.592038     1.898799      0.403278   \n",
       "std       1.645968     1.723377     2.279839     1.814406      0.786792   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%       0.000000     2.000000     3.000000     0.000000      0.000000   \n",
       "50%       1.000000     3.000000     5.000000     2.000000      0.000000   \n",
       "75%       2.000000     4.000000     6.000000     3.000000      1.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000      5.000000   \n",
       "\n",
       "            Farmer  Mid_management   Skld_labor  Unskld_labor    Soc_cls_A  \\\n",
       "count  9822.000000     9822.000000  9822.000000   9822.000000  9822.000000   \n",
       "mean      0.545714        2.877113     2.226532      2.291183     1.650682   \n",
       "std       1.106349        1.846703     1.748025      1.684008     1.742410   \n",
       "min       0.000000        0.000000     0.000000      0.000000     0.000000   \n",
       "25%       0.000000        2.000000     1.000000      1.000000     0.000000   \n",
       "50%       0.000000        3.000000     2.000000      2.000000     1.000000   \n",
       "75%       1.000000        4.000000     3.000000      3.000000     2.000000   \n",
       "max       9.000000        9.000000     9.000000      9.000000     9.000000   \n",
       "\n",
       "        Soc_cls_B1   Soc_cls_B2    Soc_cls_C    Soc_cls_D      R_house  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000  9822.000000   \n",
       "mean      1.595093     2.204744     3.742211     1.068214     4.187742   \n",
       "std       1.321487     1.534163     1.944900     1.298229     3.093127   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     2.000000     0.000000     2.000000   \n",
       "50%       2.000000     2.000000     4.000000     1.000000     4.000000   \n",
       "75%       2.000000     3.000000     5.000000     2.000000     7.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "           O_house        1_car       2_cars        N_car  Nat_Hlth_Serv  \\\n",
       "count  9822.000000  9822.000000  9822.000000  9822.000000    9822.000000   \n",
       "mean      4.819487     6.022501     1.335980     1.956730       6.254327   \n",
       "std       3.093541     1.543980     1.213627     1.596842       2.000374   \n",
       "min       0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "25%       2.000000     5.000000     0.000000     0.000000       5.000000   \n",
       "50%       5.000000     6.000000     1.000000     2.000000       7.000000   \n",
       "75%       7.000000     7.000000     2.000000     3.000000       8.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000       9.000000   \n",
       "\n",
       "       Prv_Hlth_Insur    Inc_u_30k  Inc_btw_30_45k  Inc_btw_45_75k  \\\n",
       "count     9822.000000  9822.000000     9822.000000     9822.000000   \n",
       "mean         2.750662     2.577072        3.505498        2.739462   \n",
       "std          2.002960     2.073125        1.871365        1.950625   \n",
       "min          0.000000     0.000000        0.000000        0.000000   \n",
       "25%          1.000000     1.000000        2.000000        1.000000   \n",
       "50%          2.000000     2.000000        4.000000        3.000000   \n",
       "75%          4.000000     4.000000        5.000000        4.000000   \n",
       "max          9.000000     9.000000        9.000000        9.000000   \n",
       "\n",
       "       Inc_75_122k  Inc_ovr_123k     Avg_inc       PP_cls  \\\n",
       "count  9822.000000   9822.000000  9822.00000  9822.000000   \n",
       "mean      0.808491      0.208002     3.80452     4.260334   \n",
       "std       1.173771      0.561832     1.33093     1.998913   \n",
       "min       0.000000      0.000000     0.00000     1.000000   \n",
       "25%       0.000000      0.000000     3.00000     3.000000   \n",
       "50%       0.000000      0.000000     4.00000     4.000000   \n",
       "75%       1.000000      0.000000     4.00000     6.000000   \n",
       "max       9.000000      9.000000     9.00000     8.000000   \n",
       "\n",
       "       Contri_prv_3p_insur  Firm_Contri_3p_ insur  Ag_Contri_3p_insur  \\\n",
       "count          9822.000000            9822.000000         9822.000000   \n",
       "mean              0.764915               0.038892            0.073712   \n",
       "std               0.956555               0.356924            0.507818   \n",
       "min               0.000000               0.000000            0.000000   \n",
       "25%               0.000000               0.000000            0.000000   \n",
       "50%               0.000000               0.000000            0.000000   \n",
       "75%               2.000000               0.000000            0.000000   \n",
       "max               3.000000               6.000000            4.000000   \n",
       "\n",
       "       Contri_car_pol  Contri_deliv_van_pol  Contri_motorcycle/scooter_pol  \\\n",
       "count     9822.000000           9822.000000                    9822.000000   \n",
       "mean         2.956424              0.054877                       0.170841   \n",
       "std          2.921736              0.566108                       0.888518   \n",
       "min          0.000000              0.000000                       0.000000   \n",
       "25%          0.000000              0.000000                       0.000000   \n",
       "50%          5.000000              0.000000                       0.000000   \n",
       "75%          6.000000              0.000000                       0.000000   \n",
       "max          9.000000              7.000000                       7.000000   \n",
       "\n",
       "       Contri_lorry_pol  Contri_trailer_pols  Contri_tractor_pol  \\\n",
       "count       9822.000000          9822.000000         9822.000000   \n",
       "mean           0.008858             0.019344            0.093565   \n",
       "std            0.237556             0.200885            0.604350   \n",
       "min            0.000000             0.000000            0.000000   \n",
       "25%            0.000000             0.000000            0.000000   \n",
       "50%            0.000000             0.000000            0.000000   \n",
       "75%            0.000000             0.000000            0.000000   \n",
       "max            9.000000             5.000000            7.000000   \n",
       "\n",
       "       Contri_ag_machine_pol  Contri_moped_pol  Contri_life_insur  \\\n",
       "count            9822.000000       9822.000000        9822.000000   \n",
       "mean                0.011505          0.215027           0.202301   \n",
       "std                 0.215408          0.810899           0.910574   \n",
       "min                 0.000000          0.000000           0.000000   \n",
       "25%                 0.000000          0.000000           0.000000   \n",
       "50%                 0.000000          0.000000           0.000000   \n",
       "75%                 0.000000          0.000000           0.000000   \n",
       "max                 6.000000          6.000000           9.000000   \n",
       "\n",
       "       Contri_prv_accid_insur_pol  Contri_fam_accid_insur_pol  \\\n",
       "count                 9822.000000                 9822.000000   \n",
       "mean                     0.011505                    0.018733   \n",
       "std                      0.188699                    0.213712   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.000000                    0.000000   \n",
       "50%                      0.000000                    0.000000   \n",
       "75%                      0.000000                    0.000000   \n",
       "max                      6.000000                    3.000000   \n",
       "\n",
       "       Contri_disabl_insur_pol  Contri_fire_pol  Contri_surfb_pol  \\\n",
       "count              9822.000000      9822.000000       9822.000000   \n",
       "mean                  0.023315         1.849420          0.001629   \n",
       "std                   0.375350         1.881271          0.057058   \n",
       "min                   0.000000         0.000000          0.000000   \n",
       "25%                   0.000000         0.000000          0.000000   \n",
       "50%                   0.000000         2.000000          0.000000   \n",
       "75%                   0.000000         4.000000          0.000000   \n",
       "max                   7.000000         8.000000          3.000000   \n",
       "\n",
       "       Contri_boat_pol  Contri_bike_pol  Contri_prop_insur_pol  \\\n",
       "count      9822.000000      9822.000000            9822.000000   \n",
       "mean          0.015272         0.025351               0.016697   \n",
       "std           0.244210         0.157198               0.211487   \n",
       "min           0.000000         0.000000               0.000000   \n",
       "25%           0.000000         0.000000               0.000000   \n",
       "50%           0.000000         0.000000               0.000000   \n",
       "75%           0.000000         0.000000               0.000000   \n",
       "max           6.000000         1.000000               6.000000   \n",
       "\n",
       "       Contri_ss_insur_polo  Num_prv_3p_insur  Num_firm_3p_insur  \\\n",
       "count           9822.000000       9822.000000        9822.000000   \n",
       "mean               0.045408          0.400020           0.014050   \n",
       "std                0.396983          0.492001           0.126058   \n",
       "min                0.000000          0.000000           0.000000   \n",
       "25%                0.000000          0.000000           0.000000   \n",
       "50%                0.000000          0.000000           0.000000   \n",
       "75%                0.000000          1.000000           0.000000   \n",
       "max                5.000000          2.000000           5.000000   \n",
       "\n",
       "       Num_ag_3p_insur  Num_car_pol  Num_deliv_van_pol  \\\n",
       "count      9822.000000  9822.000000        9822.000000   \n",
       "mean          0.021279     0.557218           0.011098   \n",
       "std           0.144319     0.608575           0.129928   \n",
       "min           0.000000     0.000000           0.000000   \n",
       "25%           0.000000     0.000000           0.000000   \n",
       "50%           0.000000     1.000000           0.000000   \n",
       "75%           0.000000     1.000000           0.000000   \n",
       "max           1.000000    12.000000           5.000000   \n",
       "\n",
       "       Num_motorcycle/scooter_pol  Num_lorry_pol  Num_trailer_pol  \\\n",
       "count                 9822.000000    9822.000000      9822.000000   \n",
       "mean                     0.040216       0.002240         0.011403   \n",
       "std                      0.223622       0.068402         0.116251   \n",
       "min                      0.000000       0.000000         0.000000   \n",
       "25%                      0.000000       0.000000         0.000000   \n",
       "50%                      0.000000       0.000000         0.000000   \n",
       "75%                      0.000000       0.000000         0.000000   \n",
       "max                      8.000000       4.000000         3.000000   \n",
       "\n",
       "       Num_tractor_pol  Num_ag_machines_pol  Num_moped_pol  \\\n",
       "count      9822.000000          9822.000000    9822.000000   \n",
       "mean          0.034413             0.005192       0.071065   \n",
       "std           0.249706             0.109954       0.267432   \n",
       "min           0.000000             0.000000       0.000000   \n",
       "25%           0.000000             0.000000       0.000000   \n",
       "50%           0.000000             0.000000       0.000000   \n",
       "75%           0.000000             0.000000       0.000000   \n",
       "max           6.000000             6.000000       3.000000   \n",
       "\n",
       "       Num_life_insur_pol  Num_prv_accid_insur_pol  Num_fam_ccid_insur_pol  \\\n",
       "count         9822.000000              9822.000000             9822.000000   \n",
       "mean             0.079821                 0.004582                0.007941   \n",
       "std              0.384431                 0.067535                0.088764   \n",
       "min              0.000000                 0.000000                0.000000   \n",
       "25%              0.000000                 0.000000                0.000000   \n",
       "50%              0.000000                 0.000000                0.000000   \n",
       "75%              0.000000                 0.000000                0.000000   \n",
       "max              8.000000                 1.000000                1.000000   \n",
       "\n",
       "       Num_disabl_insur_pol  Num_fire_pol  Num_surfb_pol  Num_boat_pol  \\\n",
       "count           9822.000000   9822.000000    9822.000000   9822.000000   \n",
       "mean               0.004276      0.574018       0.000916      0.005091   \n",
       "std                0.071224      0.561255       0.030258      0.077996   \n",
       "min                0.000000      0.000000       0.000000      0.000000   \n",
       "25%                0.000000      0.000000       0.000000      0.000000   \n",
       "50%                0.000000      1.000000       0.000000      0.000000   \n",
       "75%                0.000000      1.000000       0.000000      0.000000   \n",
       "max                2.000000      7.000000       1.000000      2.000000   \n",
       "\n",
       "       Num_bike_pol  Num_prop_insur_pol  num_ss_insur_pol       Target  \n",
       "count    9822.00000         9822.000000       9822.000000  9822.000000  \n",
       "mean        0.03146            0.008450          0.013846     0.059662  \n",
       "std         0.20907            0.092647          0.117728     0.236872  \n",
       "min         0.00000            0.000000          0.000000     0.000000  \n",
       "25%         0.00000            0.000000          0.000000     0.000000  \n",
       "50%         0.00000            0.000000          0.000000     0.000000  \n",
       "75%         0.00000            0.000000          0.000000     0.000000  \n",
       "max         4.00000            2.000000          2.000000     1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_td = pd.read_csv('tic_2000_train_data.csv')\n",
    "eval_df = pd.read_csv('tic_2000_eval_data.csv')#CARAVAN is renamed 'Target' in this set\n",
    "\n",
    "#renaming the training data to match the test data.\n",
    "df_td.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol', 'CARAVAN' : 'Target'},\n",
    "          inplace=True)\n",
    "eval_df.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol'},\n",
    "          inplace=True)\n",
    "\n",
    "df_list = [df_td, eval_df]\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy tables and leaving our Target variable out for the models.\n",
    "pre_enc= df.drop('Target', axis=1)\n",
    "post_enc_df = pd.get_dummies(df, prefix_sep=\"_\", columns=pre_enc.columns)\n",
    "\n",
    "new_df = post_enc_df[['Contri_boat_pol_0', 'Avg_inc_0', 'maintype_L2_10', 'Contri_fire_pol_2',\n",
    "       'Contri_ss_insur_polo_0', 'maintype_L2_5', 'maintype_L2_4', 'R_house_2',\n",
    "       'L_lvl_edu_7', 'H_lvl_edu_3', 'H_lvl_edu_0', 'L_lvl_edu_6',\n",
    "       'maintype_L2_3', '1_car_4', '1_car_2', 'L_lvl_edu_9', 'Avg_inc_2',\n",
    "       'Contri_fire_pol_1', 'Avg_inc_3', 'Contri_fire_pol_6', 'R_house_5',\n",
    "       'PP_cls_3', 'PP_cls_5', 'Contri_prv_3p_insur_1', 'Num_fire_pol_2',\n",
    "       'maintype_L2_1', 'maintype_L2_2', 'Contri_disabl_insur_pol_6',\n",
    "       'H_lvl_edu_5', 'Num_fire_pol_1', '1_car_5', '1_car_6', 'PP_cls_4',\n",
    "       'H_lvl_edu_4', 'H_lvl_edu_6', 'Contri_fire_pol_5', 'Avg_inc_5',\n",
    "       'maintype_L2_8', 'R_house_1', '1_car_9', 'L_lvl_edu_8', 'R_house_6',\n",
    "       'L_lvl_edu_2', 'maintype_L2_9', 'Contri_fire_pol_3', 'Avg_inc_4',\n",
    "       'Avg_inc_7', 'L_lvl_edu_1', 'PP_cls_8', 'R_house_0', 'L_lvl_edu_0',\n",
    "       '1_car_7', 'Contri_prv_3p_insur_2', 'H_lvl_edu_7',\n",
    "       'Contri_ss_insur_polo_4', 'Contri_fire_pol_4', 'PP_cls_7',\n",
    "       'Contri_car_pol_6', 'Contri_fam_accid_insur_pol_3','Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Negative values in data passed to MultinomialNB (input X)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5bcd7390cd34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Search the hyperparameter space based on the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mestim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Show the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hpsklearn\\estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, EX_list, valid_size, n_folds, cv_shuffle, warm_start, random_state, weights)\u001b[0m\n\u001b[0;32m    785\u001b[0m                 increment = min(self.fit_increment,\n\u001b[0;32m    786\u001b[0m                                 adjusted_max_evals - len(self.trials.trials))\n\u001b[1;32m--> 787\u001b[1;33m                 \u001b[0mfit_iter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mincrement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m                     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdump_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hpsklearn\\estimator.py\u001b[0m in \u001b[0;36mfit_iter\u001b[1;34m(self, X, y, EX_list, valid_size, n_folds, cv_shuffle, warm_start, random_state, weights, increment)\u001b[0m\n\u001b[0;32m    695\u001b[0m                               \u001b[1;31m#    so we notice them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                               \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                               \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# -- in case no success so far\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                              )\n\u001b[0;32m    699\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    480\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         )\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         )\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    284\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             )\n\u001b[1;32m--> 894\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hpsklearn\\estimator.py\u001b[0m in \u001b[0;36mfn_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mfn_rval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'return'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfn_rval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mfn_rval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# -- remove potentially large objects from the rval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = new_df.drop('Target', axis=1)\n",
    "y = new_df.Target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "\n",
    "# Instantiate a HyperoptEstimator with the search space and number of evaluations\n",
    "\n",
    "estim = HyperoptEstimator(classifier=multinomial_nb('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, plot_roc_curve, classification_report, balanced_accuracy_score, coverage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.030509817593472984,\n",
    "                           loss='exponential', max_features=0.36684107529168053,\n",
    "                           min_samples_leaf=8, n_estimators=287, presort='auto',\n",
    "                           random_state=3)\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"accuracy score\" '\\n', accuracy_score(y_test, predictions))\n",
    "print(\"model confusion matrix\" '\\n', confusion_matrix(y_test, predictions, normalize='all'))\n",
    "print(\"classification_report\" '\\n', classification_report(y_test, predictions),'\\n')\n",
    "ax = plt.gca()\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "disp = plot_roc_curve(classifier, X_test, y_test, ax=ax, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:39<00:00, 39.76s/trial, best loss: 0.0693384223918575]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.26trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.21s/trial, best loss: 0.058524173027989845]\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.36s/trial, best loss: 0.058524173027989845]\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.26s/trial, best loss: 0.058524173027989845]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.99trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.70trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 8/8 [00:03<00:00,  2.27trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.29trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 10/10 [00:23<00:00,  2.34s/trial, best loss: 0.058524173027989845]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.09trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 12/12 [00:29<00:00,  2.44s/trial, best loss: 0.058524173027989845]\n",
      "100%|██████████| 13/13 [00:01<00:00,  9.10trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 14/14 [00:01<00:00,  8.02trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 15/15 [00:01<00:00, 10.05trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 16/16 [00:03<00:00,  5.01trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 17/17 [00:04<00:00,  4.00trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 18/18 [00:03<00:00,  5.78trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 19/19 [00:02<00:00,  7.40trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.82trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 21/21 [00:01<00:00, 14.42trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 22/22 [00:01<00:00, 15.63trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 23/23 [00:01<00:00, 14.91trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 24/24 [00:01<00:00, 15.49trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 25/25 [00:06<00:00,  3.98trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 26/26 [00:01<00:00, 16.63trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 27/27 [00:01<00:00, 17.05trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 28/28 [00:03<00:00,  9.00trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 29/29 [00:02<00:00, 12.64trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 30/30 [00:02<00:00, 12.32trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 31/31 [00:02<00:00, 12.43trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 32/32 [00:01<00:00, 23.86trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 33/33 [00:01<00:00, 21.40trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 34/34 [00:02<00:00, 12.32trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 35/35 [00:07<00:00,  4.49trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 36/36 [00:01<00:00, 24.29trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 37/37 [00:06<00:00,  5.33trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 38/38 [00:18<00:00,  2.09trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 39/39 [00:01<00:00, 26.81trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 40/40 [00:03<00:00, 10.15trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 41/41 [00:02<00:00, 18.60trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 42/42 [00:04<00:00,  9.15trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 43/43 [00:01<00:00, 27.00trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 44/44 [00:51<00:00,  1.16s/trial, best loss: 0.057888040712468225]\n",
      "100%|██████████| 45/45 [00:03<00:00, 14.94trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 46/46 [00:01<00:00, 30.12trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 47/47 [00:01<00:00, 25.16trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 48/48 [00:24<00:00,  1.94trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 49/49 [00:02<00:00, 18.41trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.91trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 51/51 [00:02<00:00, 24.91trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 52/52 [00:01<00:00, 38.69trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 53/53 [00:01<00:00, 36.27trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 54/54 [00:52<00:00,  1.03trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 55/55 [00:01<00:00, 36.08trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 56/56 [00:01<00:00, 36.33trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 57/57 [00:01<00:00, 41.39trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 58/58 [00:19<00:00,  3.02trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 59/59 [00:02<00:00, 24.89trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 60/60 [00:01<00:00, 32.08trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 61/61 [00:02<00:00, 24.46trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 62/62 [00:01<00:00, 36.85trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 63/63 [00:02<00:00, 26.13trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 64/64 [00:01<00:00, 45.46trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 65/65 [00:02<00:00, 22.70trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 66/66 [00:08<00:00,  8.12trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 67/67 [00:14<00:00,  4.49trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 68/68 [00:05<00:00, 11.80trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 69/69 [00:13<00:00,  5.22trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 70/70 [00:01<00:00, 48.04trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 71/71 [00:16<00:00,  4.36trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 72/72 [00:01<00:00, 42.69trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 73/73 [00:02<00:00, 29.63trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 74/74 [00:02<00:00, 30.25trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 75/75 [00:02<00:00, 32.00trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 76/76 [00:01<00:00, 39.77trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 77/77 [00:01<00:00, 42.48trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 78/78 [00:01<00:00, 50.94trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.01trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 80/80 [00:01<00:00, 40.87trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 81/81 [00:02<00:00, 30.19trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 82/82 [00:01<00:00, 46.93trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 83/83 [00:01<00:00, 56.82trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 84/84 [00:01<00:00, 61.76trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 85/85 [00:01<00:00, 59.45trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 86/86 [00:01<00:00, 50.66trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 87/87 [00:01<00:00, 53.33trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 88/88 [00:05<00:00, 17.33trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 89/89 [00:16<00:00,  5.42trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 90/90 [00:01<00:00, 53.56trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 91/91 [00:01<00:00, 62.83trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 92/92 [00:01<00:00, 61.82trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 93/93 [00:01<00:00, 57.61trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 94/94 [00:01<00:00, 56.99trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 95/95 [00:01<00:00, 62.12trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 96/96 [00:01<00:00, 66.70trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 97/97 [00:02<00:00, 41.26trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 98/98 [00:02<00:00, 45.02trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 99/99 [00:05<00:00, 19.68trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 100/100 [00:33<00:00,  2.99trial/s, best loss: 0.057888040712468225]\n",
      "0.9394402035623409\n",
      "{'learner': RandomForestClassifier(max_depth=3, max_features=None, n_estimators=615,\n",
      "                       n_jobs=1, random_state=0, verbose=False), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "estim_rf = HyperoptEstimator(classifier=random_forest('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_rf.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_rf.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_rf.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_gbt = HyperoptEstimator(classifier=gradient_boosting('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_gbt.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_gbt.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_gbt.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/trial, best loss: 0.07697201017811706]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.55trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.38trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.99trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.92trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 6/6 [00:01<00:00,  4.62trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.49trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 8/8 [00:01<00:00,  6.04trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.59trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.87trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 11/11 [00:01<00:00,  8.65trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.23trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 13/13 [00:01<00:00, 10.17trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.86trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 15/15 [00:01<00:00, 11.95trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 16/16 [00:01<00:00, 12.23trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 17/17 [00:01<00:00, 13.39trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 18/18 [00:01<00:00, 14.04trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 19/19 [00:01<00:00, 14.82trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 20/20 [00:01<00:00, 15.43trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 21/21 [00:01<00:00, 15.49trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 22/22 [00:01<00:00, 16.07trial/s, best loss: 0.07697201017811706]\n",
      "100%|██████████| 23/23 [00:01<00:00, 16.21trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 24/24 [00:01<00:00, 16.48trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.80trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 26/26 [00:01<00:00, 19.45trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 27/27 [00:01<00:00, 19.61trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 28/28 [00:01<00:00, 20.86trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 29/29 [00:01<00:00, 20.65trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 30/30 [00:01<00:00, 23.29trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 31/31 [00:01<00:00, 22.53trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 32/32 [00:01<00:00, 23.36trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 33/33 [00:01<00:00, 23.45trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 34/34 [00:01<00:00, 26.62trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 35/35 [00:01<00:00, 26.33trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 36/36 [00:01<00:00, 25.47trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 37/37 [00:01<00:00, 26.09trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 38/38 [00:01<00:00, 28.42trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 39/39 [00:01<00:00, 29.98trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 40/40 [00:01<00:00, 28.43trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 41/41 [00:01<00:00, 30.59trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 42/42 [00:01<00:00, 32.28trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 43/43 [00:01<00:00, 32.38trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 44/44 [00:01<00:00, 34.18trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 45/45 [00:01<00:00, 33.96trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 46/46 [00:01<00:00, 29.87trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 47/47 [00:01<00:00, 32.75trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 48/48 [00:01<00:00, 29.73trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 49/49 [00:01<00:00, 35.82trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 50/50 [00:01<00:00, 32.65trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 51/51 [00:01<00:00, 37.94trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 52/52 [00:01<00:00, 32.95trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 53/53 [00:01<00:00, 39.20trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 54/54 [00:01<00:00, 35.01trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 55/55 [00:01<00:00, 39.51trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 56/56 [00:01<00:00, 35.48trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 57/57 [00:01<00:00, 41.39trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 58/58 [00:01<00:00, 35.62trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 59/59 [00:01<00:00, 43.22trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 60/60 [00:01<00:00, 36.80trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 61/61 [00:01<00:00, 42.08trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 62/62 [00:01<00:00, 39.97trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 63/63 [00:01<00:00, 43.96trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 64/64 [00:01<00:00, 41.12trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 65/65 [00:02<00:00, 30.68trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 66/66 [00:01<00:00, 41.50trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 67/67 [00:01<00:00, 42.32trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 68/68 [00:01<00:00, 48.43trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 69/69 [00:01<00:00, 43.63trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 70/70 [00:01<00:00, 49.22trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 71/71 [00:01<00:00, 44.62trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 72/72 [00:01<00:00, 36.87trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 73/73 [00:01<00:00, 52.70trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 74/74 [00:01<00:00, 44.22trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 75/75 [00:01<00:00, 52.48trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 76/76 [00:01<00:00, 48.68trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 77/77 [00:01<00:00, 55.49trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 78/78 [00:01<00:00, 48.95trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 79/79 [00:01<00:00, 54.36trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 80/80 [00:01<00:00, 49.93trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 81/81 [00:01<00:00, 60.04trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 82/82 [00:01<00:00, 52.79trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 83/83 [00:01<00:00, 55.88trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 84/84 [00:01<00:00, 57.06trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 85/85 [00:01<00:00, 63.76trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 86/86 [00:01<00:00, 63.70trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 87/87 [00:01<00:00, 66.03trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 88/88 [00:01<00:00, 68.10trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 89/89 [00:01<00:00, 66.91trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 90/90 [00:01<00:00, 55.07trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 91/91 [00:03<00:00, 25.93trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 92/92 [00:01<00:00, 64.64trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 93/93 [00:01<00:00, 59.99trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 94/94 [00:01<00:00, 68.41trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 95/95 [00:01<00:00, 59.40trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 96/96 [00:01<00:00, 66.29trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 97/97 [00:01<00:00, 60.61trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 98/98 [00:01<00:00, 71.01trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 99/99 [00:01<00:00, 61.17trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 100/100 [00:01<00:00, 69.53trial/s, best loss: 0.058524173027989845]\n",
      "0.9399491094147583\n",
      "{'learner': GaussianNB(), 'preprocs': (PCA(n_components=8, whiten=True),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "estim_guas = HyperoptEstimator(classifier=gaussian_nb('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_guas.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_guas.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_guas.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_find = HyperoptEstimator( algo=tpe.suggest, \n",
    "                            max_evals=150, \n",
    "                            trial_timeout=60 )\n",
    "\n",
    "estim_find.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "# 1.0\n",
    "\n",
    "print( estim_find.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import extra_trees\n",
    "\n",
    "estim_et = HyperoptEstimator(classifier=extra_trees('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_et.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_et.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_et.best_model() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/trial, best loss: 0.06997455470737912]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.50trial/s, best loss: 0.06997455470737912]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.12trial/s, best loss: 0.06870229007633588]\n",
      "100%|██████████| 4/4 [00:01<00:00,  3.11trial/s, best loss: 0.06870229007633588]\n",
      "100%|██████████| 5/5 [00:01<00:00,  3.90trial/s, best loss: 0.06870229007633588]\n",
      "100%|██████████| 6/6 [00:01<00:00,  4.63trial/s, best loss: 0.06870229007633588]\n",
      "100%|██████████| 7/7 [00:01<00:00,  5.38trial/s, best loss: 0.060432569974554706]\n",
      "100%|██████████| 8/8 [00:01<00:00,  4.01trial/s, best loss: 0.060432569974554706]\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.18trial/s, best loss: 0.060432569974554706]\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.90trial/s, best loss: 0.059796437659033086]\n",
      "100%|██████████| 11/11 [00:01<00:00,  8.02trial/s, best loss: 0.059796437659033086]\n",
      "100%|██████████| 12/12 [00:01<00:00,  9.49trial/s, best loss: 0.059796437659033086]\n",
      "100%|██████████| 13/13 [00:01<00:00,  9.13trial/s, best loss: 0.059796437659033086]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.94trial/s, best loss: 0.059796437659033086]\n",
      "100%|██████████| 15/15 [00:01<00:00, 11.23trial/s, best loss: 0.059796437659033086]\n",
      "100%|██████████| 16/16 [00:01<00:00, 12.59trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 17/17 [00:01<00:00, 12.58trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 18/18 [00:01<00:00, 13.28trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 19/19 [00:01<00:00, 14.59trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 20/20 [00:01<00:00, 15.21trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 21/21 [00:01<00:00, 15.84trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 22/22 [00:01<00:00, 17.49trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 23/23 [00:01<00:00, 17.12trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 24/24 [00:01<00:00, 18.65trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 25/25 [00:01<00:00, 19.06trial/s, best loss: 0.058524173027989845]\n",
      "100%|██████████| 26/26 [00:01<00:00, 20.40trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 27/27 [00:01<00:00, 20.90trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 28/28 [00:01<00:00, 21.91trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 29/29 [00:01<00:00, 21.91trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 30/30 [00:01<00:00, 23.54trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 31/31 [00:01<00:00, 23.71trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 32/32 [00:01<00:00, 24.90trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 33/33 [00:01<00:00, 25.41trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 34/34 [00:01<00:00, 26.60trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 35/35 [00:01<00:00, 26.57trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 36/36 [00:01<00:00, 28.28trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 37/37 [00:01<00:00, 28.21trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 38/38 [00:01<00:00, 29.50trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 39/39 [00:01<00:00, 30.15trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 40/40 [00:01<00:00, 29.66trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 41/41 [00:01<00:00, 31.50trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 42/42 [00:01<00:00, 31.30trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 43/43 [00:01<00:00, 31.50trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 44/44 [00:01<00:00, 33.83trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 45/45 [00:01<00:00, 34.67trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 46/46 [00:01<00:00, 33.62trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 47/47 [00:01<00:00, 36.40trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 48/48 [00:01<00:00, 37.54trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 49/49 [00:01<00:00, 36.60trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 50/50 [00:01<00:00, 39.55trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 51/51 [00:01<00:00, 37.38trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 52/52 [00:01<00:00, 39.65trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 53/53 [00:01<00:00, 40.06trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 54/54 [00:01<00:00, 42.15trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 55/55 [00:01<00:00, 41.13trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 56/56 [00:01<00:00, 40.97trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 57/57 [00:01<00:00, 43.91trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 58/58 [00:01<00:00, 40.55trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 59/59 [00:01<00:00, 43.83trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 60/60 [00:01<00:00, 42.50trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 61/61 [00:01<00:00, 38.70trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 62/62 [00:01<00:00, 45.38trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 63/63 [00:01<00:00, 39.49trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 64/64 [00:01<00:00, 44.06trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 65/65 [00:01<00:00, 39.53trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 66/66 [00:01<00:00, 45.46trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 67/67 [00:01<00:00, 41.59trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 68/68 [00:01<00:00, 48.36trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 69/69 [00:01<00:00, 44.41trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 70/70 [00:01<00:00, 51.85trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 71/71 [00:01<00:00, 45.69trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 72/72 [00:01<00:00, 53.31trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 73/73 [00:01<00:00, 45.59trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 74/74 [00:01<00:00, 54.69trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 75/75 [00:01<00:00, 47.85trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 76/76 [00:01<00:00, 54.42trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 77/77 [00:01<00:00, 46.95trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 78/78 [00:01<00:00, 57.13trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 79/79 [00:01<00:00, 60.14trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 80/80 [00:01<00:00, 60.60trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 81/81 [00:01<00:00, 62.65trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 82/82 [00:01<00:00, 59.37trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 83/83 [00:01<00:00, 63.30trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 84/84 [00:01<00:00, 63.70trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 85/85 [00:01<00:00, 66.12trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 86/86 [00:01<00:00, 65.31trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 87/87 [00:01<00:00, 64.74trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 88/88 [00:01<00:00, 67.17trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 89/89 [00:01<00:00, 66.41trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 90/90 [00:01<00:00, 69.01trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 91/91 [00:01<00:00, 69.62trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 92/92 [00:01<00:00, 71.26trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 93/93 [00:01<00:00, 70.47trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 94/94 [00:01<00:00, 71.31trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 95/95 [00:01<00:00, 70.86trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 96/96 [00:01<00:00, 75.64trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 97/97 [00:01<00:00, 73.90trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 98/98 [00:01<00:00, 76.26trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 99/99 [00:01<00:00, 76.21trial/s, best loss: 0.057888040712468225]\n",
      "100%|██████████| 100/100 [00:01<00:00, 76.18trial/s, best loss: 0.057888040712468225]\n",
      "0.9374045801526718\n",
      "{'learner': DecisionTreeClassifier(max_features='log2', min_samples_leaf=4,\n",
      "                       min_samples_split=10, presort=False, random_state=1,\n",
      "                       splitter='random'), 'preprocs': (MinMaxScaler(feature_range=(-1.0, 1.0)),), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Threadripper\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\tree\\_classes.py:327: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import decision_tree\n",
    "\n",
    "estim_knn = HyperoptEstimator(classifier=decision_tree('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_knn.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_knn.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_knn.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decision_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-15a2d4130caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m estim_dt = HyperoptEstimator(classifier=decision_tree('my_clf'),\n\u001b[0m\u001b[0;32m      2\u001b[0m                           \u001b[0mpreprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0many_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_pre'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                           trial_timeout=120)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decision_tree' is not defined"
     ]
    }
   ],
   "source": [
    "estim_dt = HyperoptEstimator(classifier=decision_tree('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_dt.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_dt.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_dt.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_adab = HyperoptEstimator(classifier=ada_boost('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_adab.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_adab.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_adab.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_lda = HyperoptEstimator(classifier=linear_discriminant_analysis('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_lda.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_lda.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_lda.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_qda = HyperoptEstimator(classifier=quadratic_discriminant_analysis('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_qda.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_qda.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_qda.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_xgb = HyperoptEstimator(classifier=xgboost_classification('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_xgb.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_xgb.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
