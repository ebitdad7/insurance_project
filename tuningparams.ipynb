{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hpsklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e8550f98558e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhpsklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperoptEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0many_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0many_preprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient_boosting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultinomial_nb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hpsklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ppscore as pps\n",
    "import statsmodels as sm\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, random_forest, gaussian_nb, gradient_boosting, multinomial_nb\n",
    "from hyperopt import tpe\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target feature in Training Data; Balance \n",
      " 0    5474\n",
      "1     348\n",
      "Name: CARAVAN, dtype: int64\n",
      "Target feature in Target Data; Balance \n",
      " 0    3762\n",
      "1     238\n",
      "Name: Target, dtype: int64\n",
      "Training Features Dataset; Shape (5822, 86)\n",
      "Eval Features Dataset; Shape (4000, 85)\n",
      "Target Feature Dataset; Shape (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_td = pd.read_csv('tic_2000_train_data.csv')\n",
    "eval_df = pd.read_csv('tic_2000_eval_data.csv')#CARAVAN is renamed 'Target' in this set\n",
    "\n",
    "#renaming the training data to match the test data.\n",
    "df_td.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol', 'CARAVAN' : 'Target'},\n",
    "          inplace=True)\n",
    "eval_df.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol'},\n",
    "          inplace=True)\n",
    "\n",
    "df_list = [df_td, eval_df]\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy tables and leaving our Target variable out for the models.\n",
    "pre_enc= df.drop('Target', axis=1)\n",
    "post_enc_df = pd.get_dummies(df, prefix_sep=\"_\", columns=pre_enc.columns)\n",
    "\n",
    "new_df = post_enc_df[['Contri_boat_pol_0', 'Avg_inc_0', 'maintype_L2_10', 'Contri_fire_pol_2',\n",
    "       'Contri_ss_insur_polo_0', 'maintype_L2_5', 'maintype_L2_4', 'R_house_2',\n",
    "       'L_lvl_edu_7', 'H_lvl_edu_3', 'H_lvl_edu_0', 'L_lvl_edu_6',\n",
    "       'maintype_L2_3', '1_car_4', '1_car_2', 'L_lvl_edu_9', 'Avg_inc_2',\n",
    "       'Contri_fire_pol_1', 'Avg_inc_3', 'Contri_fire_pol_6', 'R_house_5',\n",
    "       'PP_cls_3', 'PP_cls_5', 'Contri_prv_3p_insur_1', 'Num_fire_pol_2',\n",
    "       'maintype_L2_1', 'maintype_L2_2', 'Contri_disabl_insur_pol_6',\n",
    "       'H_lvl_edu_5', 'Num_fire_pol_1', '1_car_5', '1_car_6', 'PP_cls_4',\n",
    "       'H_lvl_edu_4', 'H_lvl_edu_6', 'Contri_fire_pol_5', 'Avg_inc_5',\n",
    "       'maintype_L2_8', 'R_house_1', '1_car_9', 'L_lvl_edu_8', 'R_house_6',\n",
    "       'L_lvl_edu_2', 'maintype_L2_9', 'Contri_fire_pol_3', 'Avg_inc_4',\n",
    "       'Avg_inc_7', 'L_lvl_edu_1', 'PP_cls_8', 'R_house_0', 'L_lvl_edu_0',\n",
    "       '1_car_7', 'Contri_prv_3p_insur_2', 'H_lvl_edu_7',\n",
    "       'Contri_ss_insur_polo_4', 'Contri_fire_pol_4', 'PP_cls_7',\n",
    "       'Contri_car_pol_6', 'Contri_fam_accid_insur_pol_3','Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = new_df.drop('Target', axis=1)\n",
    "y = new_df.Target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "\n",
    "# Instantiate a HyperoptEstimator with the search space and number of evaluations\n",
    "\n",
    "estim = HyperoptEstimator(classifier=gradient_boosting('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, plot_roc_curve, classification_report, balanced_accuracy_score, coverage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.030509817593472984,\n",
    "                           loss='exponential', max_features=0.36684107529168053,\n",
    "                           min_samples_leaf=8, n_estimators=287, presort='auto',\n",
    "                           random_state=3)\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"accuracy score\" '\\n', accuracy_score(y_test, predictions))\n",
    "print(\"model confusion matrix\" '\\n', confusion_matrix(y_test, predictions, normalize='all'))\n",
    "print(\"classification_report\" '\\n', classification_report(y_test, predictions),'\\n')\n",
    "ax = plt.gca()\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "disp = plot_roc_curve(classifier, X_test, y_test, ax=ax, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_rf = HyperoptEstimator(classifier=random_forest('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_rf.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_rf.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_rf.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_gbt = HyperoptEstimator(classifier=gradient_boosting('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_gbt.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_gbt.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_gbt.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_guas = HyperoptEstimator(classifier=gaussian_nb('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_guas.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_guas.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_guas.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_find = HyperoptEstimator( algo=tpe.suggest, \n",
    "                            max_evals=150, \n",
    "                            trial_timeout=60 )\n",
    "\n",
    "estim_find.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "# 1.0\n",
    "\n",
    "print( estim_find.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import extra_trees\n",
    "\n",
    "estim_et = HyperoptEstimator(classifier=extra_trees('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_et.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_et.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_et.best_model() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import knn, decision_tree, ada_boost, linear_discriminant_analysis, quadratic_discriminant_analysis, xgboost_classification\n",
    "\n",
    "estim_knn = HyperoptEstimator(classifier=knn('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_knn.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_knn.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_knn.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_dt = HyperoptEstimator(classifier=decision_tree('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_dt.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_dt.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_dt.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_adab = HyperoptEstimator(classifier=ada_boost('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_adab.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_adab.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_adab.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_lda = HyperoptEstimator(classifier=linear_discriminant_analysis('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_lda.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_lda.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_lda.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_qda = HyperoptEstimator(classifier=quadratic_discriminant_analysis('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_qda.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_qda.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_qda.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_xgb = HyperoptEstimator(classifier=xgboost_classification('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_xgb.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_xgb.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
