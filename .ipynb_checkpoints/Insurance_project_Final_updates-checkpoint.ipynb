{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ppscore as pps\n",
    "import statsmodels as sm\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "MAX_EVALS = 500\n",
    "N_FOLDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I merged the excel files prior for ease of access\n",
    "pd.set_option('display.max_columns', None)\n",
    "origin_comp = pd.read_csv('tic_origin.csv')\n",
    "\n",
    "#separating data into \n",
    "train = origin_comp[origin_comp['ORIGIN'] == 'train']\n",
    "test = origin_comp[origin_comp['ORIGIN'] == 'test']\n",
    "\n",
    "# Extract the labels and format properly\n",
    "train_labels = np.array(train['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "test_labels = np.array(test['CARAVAN'].astype(np.int32)).reshape((-1,))\n",
    "\n",
    "# Drop the unneeded columns\n",
    "train = train.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "test = test.drop(columns = ['ORIGIN', 'CARAVAN'])\n",
    "\n",
    "# Convert to numpy array for splitting in cross validation\n",
    "features = np.array(train)\n",
    "test_features = np.array(test)\n",
    "labels = train_labels[:]\n",
    "\n",
    "print('Train shape: ', train.shape)\n",
    "print('Test shape: ', test.shape)\n",
    "train.head()\n",
    "\n",
    "#https://www.kaggle.com/kushshah95/the-insurance-company-tic-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(labels, edgecolor = 'k'); \n",
    "plt.xlabel('Label'); plt.ylabel('Count'); plt.title('Counts of Labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First thoughts:\n",
    "\n",
    "This is an imbalanced class problem since there are more observations where there is no insurance policy (0) compared to where there is an insurance policy (1). This being the case, ROC and AUC becomes an important factor in how we determine accuracy. A resampling method such as upsampling/downsampling, can be used on the majority observation to deal with this issue as well.\n",
    "\n",
    "\n",
    "### In this problem, I will use resampling, hyperparameter tuning, and feature selection to achieve better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming variables to easy reading\n",
    "train.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur_L4','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol'},\n",
    "          inplace=True)\n",
    "\n",
    "test.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur_L4','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol'},\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset had been pre-encoded to remove strings, but further improvements can be made to make the data more readable.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original dataset getting dummies.\n",
    "pre_enc= ['subtype_L0', 'age_L1', 'maintype_L2']\n",
    "post_enc_df = pd.get_dummies(df_td, prefix_sep=\"_\", columns=pre_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rebalancing data for a 5-1 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "#Creating a 5-1 ratio to test how this effects that data.\n",
    "# separate minority and majority classes\n",
    "no_policy = post_enc_df[post_enc_df.Target==0][:1740]\n",
    "has_policy = post_enc_df[post_enc_df.Target==1]\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([no_policy, has_policy])\n",
    "\n",
    "new_df = upsampled.sample(frac=1)\n",
    "\n",
    "# check new class counts\n",
    "print(new_df.Target.value_counts())\n",
    "print(new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#importing required modules to see impacts of different feature selection methods\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, plot_roc_curve, classification_report, balanced_accuracy_score, coverage_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "start = timer()\n",
    "train_time = timer() - start\n",
    "\n",
    "def clf_model_comp(df):\n",
    "    classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=15, min_samples_split=5),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    AdaBoostClassifier(),\n",
    "    lgb.LGBMClassifier(),\n",
    "    MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    ]\n",
    "    \n",
    "    # Separating out the features\n",
    "    X =  features\n",
    "    # Separating out the target\n",
    "    y = labels\n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)    \n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "        model = classifier.fit(X_train, y_train)\n",
    "        predictions = classifier.predict(X_test)\n",
    "        print(classifier)\n",
    "        print('The Training F1 Score is', f1_score(classifier.predict(X_train), y_train))\n",
    "        print('The Testing F1 Score is', f1_score(predictions, y_test))\n",
    "        print(\"accuracy score\" '\\n', accuracy_score(y_test, predictions))\n",
    "        print(\"balanced_accuracy_score\" '\\n', balanced_accuracy_score(y_test, predictions))\n",
    "        print(\"model confusion matrix\" '\\n', confusion_matrix(y_test, predictions, normalize='all'))\n",
    "        print(\"classification_report\" '\\n', classification_report(y_test, predictions),'\\n')\n",
    "        ax = plt.gca()\n",
    "        plt.rcParams['figure.figsize'] = (10, 10)\n",
    "        disp = plot_roc_curve(classifier, X_test, y_test, ax=ax, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_comp(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the important features for the dataset\n",
    "\n",
    "I will use the Embedded method and then Chi-squared to select features in the dataset in order to narrow down my search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "X =  new_df.drop('Target', axis=1) #df_td.drop('Target', axis=1)# train_feat\n",
    "# Separating out the target\n",
    "y = new_df.Target #df_td.Target#target_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First I am using the Embedded method to narrow down my search. \n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "\n",
    "reg = LassoCV(max_iter = 10000, tol=0.00001)\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoCV().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 30)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_col = new_df[['Contri_boat_pol', 'Contri_prv_3p_insur_L4_2', 'Contri_car_pol', 'subtype_L0_8',\n",
    "                   'Contri_disabl_insur_pol','H_lvl_edu','Contri_fire_pol','Contri_ss_insur_polo','Inc_75_122k','Mid_management',\n",
    "                   'Protestant','Soc_cls_C','PP_cls','1_car','Married','maintype_L2_2','H_status','Inc_btw_30_45k','Avg_inc','M_lvl_edu',\n",
    "                   'Nat_Hlth_Serv','O_religion','Skld_labor','Prv_Hlth_Insur','maintype_L2_3','R_house','L_lvl_edu','Farmer','Living_together',\n",
    "                   'Ag_Contri_3p_insur','Inc_ovr_123k', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf_model_comp(lasso_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soec_df = df_td.drop(df_td.iloc[:, 42:85])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now using the Chi-Squared method\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "chi_scores = chi2(X,y)\n",
    "p_values = pd.Series(chi_scores[1],index = X.columns)\n",
    "p_values.sort_values(ascending = False , inplace = True)\n",
    "matplotlib.rcParams['figure.figsize'] = (30, 10)\n",
    "p_values.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Hyperparameter tuning using Hyperopt for GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from timeit import default_timer as timer\n",
    "# Model with default hyperparameters\n",
    "model = lgb.LGBMClassifier()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "model.fit(features, labels)\n",
    "train_time = timer() - start\n",
    "\n",
    "predictions = model.predict_proba(test_features)[:, 1]\n",
    "auc = roc_auc_score(test_labels, predictions)\n",
    "\n",
    "print('The baseline score on the test set is {:.4f}.'.format(auc))\n",
    "print('The baseline training time is {:.4f} seconds'.format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'num_leaves': list(range(30, 150)),\n",
    "    'learning_rate': list(np.logspace(np.log(0.005), np.log(0.2), base = np.exp(1), num = 1000)),\n",
    "    'subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'min_child_samples': list(range(20, 500, 5)),\n",
    "    'reg_alpha': list(np.linspace(0, 1)),\n",
    "    'reg_lambda': list(np.linspace(0, 1)),\n",
    "    'colsample_bytree': list(np.linspace(0.6, 1, 10))\n",
    "}\n",
    "\n",
    "# Subsampling (only applicable with 'goss')\n",
    "subsample_dist = list(np.linspace(0.5, 1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(param_grid['learning_rate'], color = 'r', edgecolor = 'k');\n",
    "plt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(param_grid['num_leaves'], color = 'm', edgecolor = 'k')\n",
    "plt.xlabel('Learning Number of Leaves', size = 14); plt.ylabel('Count', size = 14); plt.title('Number of Leaves Distribution', size = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample parameters for gbm\n",
    "params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = random.sample(subsample_dist, 1)[0] if params['boosting_type'] != 'goss' else 1.0\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lgb dataset\n",
    "train_set = lgb.Dataset(features, label = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross validation with 10 folds\n",
    "r = lgb.cv(params, train_set, num_boost_round = 10000, nfold = 10, metrics = 'auc', \n",
    "           early_stopping_rounds = 100, verbose_eval = False, seed = 50)\n",
    "\n",
    "# Highest score\n",
    "r_best = np.max(r['auc-mean'])\n",
    "\n",
    "# Standard deviation of best score\n",
    "r_best_std = r['auc-stdv'][np.argmax(r['auc-mean'])]\n",
    "\n",
    "print('The maximium ROC AUC on the validation set was {:.5f} with std of {:.5f}.'.format(r_best, r_best_std))\n",
    "print('The ideal number of iterations was {}.'.format(np.argmax(r['auc-mean']) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to hold cv results\n",
    "random_results = pd.DataFrame(columns = ['loss', 'params', 'iteration', 'estimators', 'time'],\n",
    "                       index = list(range(MAX_EVALS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_objective(params, iteration, n_folds = N_FOLDS):\n",
    "    \"\"\"Random search objective function. Takes in hyperparameters\n",
    "       and returns a list of results to be saved.\"\"\"\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    end = timer()\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "    \n",
    "    # Return list of results\n",
    "    return [loss, params, iteration, n_estimators, end - start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "random.seed(50)\n",
    "\n",
    "# Iterate through the specified number of evaluations\n",
    "for i in range(MAX_EVALS):\n",
    "    \n",
    "    # Randomly sample parameters for gbm\n",
    "    params = {key: random.sample(value, 1)[0] for key, value in param_grid.items()}\n",
    "    \n",
    "    print(params)\n",
    "    \n",
    "    if params['boosting_type'] == 'goss':\n",
    "        # Cannot subsample with goss\n",
    "        params['subsample'] = 1.0\n",
    "    else:\n",
    "        # Subsample supported for gdbt and dart\n",
    "        params['subsample'] = random.sample(subsample_dist, 1)[0]\n",
    "        \n",
    "        \n",
    "    results_list = random_objective(params, i)\n",
    "    \n",
    "    # Add results to next row in dataframe\n",
    "    random_results.loc[i, :] = results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort results by best validation score\n",
    "random_results.sort_values('loss', ascending = True, inplace = True)\n",
    "random_results.reset_index(inplace = True, drop = True)\n",
    "random_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results.loc[0, 'params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters and number of estimators\n",
    "best_random_params = random_results.loc[0, 'params'].copy()\n",
    "best_random_estimators = int(random_results.loc[0, 'estimators'])\n",
    "best_random_model = lgb.LGBMClassifier(n_estimators=best_random_estimators, n_jobs = -1, \n",
    "                                       objective = 'binary', **best_random_params, random_state = 50)\n",
    "\n",
    "# Fit on the training data\n",
    "best_random_model.fit(features, labels)\n",
    "\n",
    "# Make test predictions\n",
    "predictions = best_random_model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "\n",
    "print('The best model from random search scores {:.4f} on the test data.'.format(roc_auc_score(test_labels, predictions)))\n",
    "print('This was achieved using {} search iterations.'.format(random_results.loc[0, 'iteration']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "#Creating Objective function for Gradient Boosting. \n",
    "\n",
    "def objective(params, n_folds = N_FOLDS):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Retrieve the subsample if present otherwise set to 1.0\n",
    "    subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type\n",
    "    params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "    params['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        params[parameter_name] = int(params[parameter_name])\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(params, train_set, num_boost_round = 10000, nfold = n_folds, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "    \n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = np.max(cv_results['auc-mean'])\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = int(np.argmax(cv_results['auc-mean']) + 1)\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(out_file, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, params, ITERATION, n_estimators, run_time])\n",
    "    \n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'params': params, 'iteration': ITERATION,\n",
    "            'estimators': n_estimators, \n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "\n",
    "# Create the learning rate\n",
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_dist = []\n",
    "\n",
    "# Draw 10000 samples from the learning rate domain\n",
    "for _ in range(10000):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\n",
    "plt.title('Learning Rate Distribution', size = 18); \n",
    "plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete uniform distribution\n",
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 30, 150, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "# Sample 10000 times from the number of leaves distribution\n",
    "for _ in range(10000):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "# kdeplot\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(num_leaves_dist, linewidth = 2, shade = True);\n",
    "plt.title('Number of Leaves Distribution', size = 18); plt.xlabel('Number of Leaves', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# boosting type domain \n",
    "boosting_type = {'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}])}\n",
    "\n",
    "# Draw a sample\n",
    "params = sample(boosting_type)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the subsample if present otherwise set to 1.0\n",
    "subsample = params['boosting_type'].get('subsample', 1.0)\n",
    "\n",
    "# Extract the boosting type\n",
    "params['boosting_type'] = params['boosting_type']['boosting_type']\n",
    "params['subsample'] = subsample\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                                 {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the full space\n",
    "x = sample(space)\n",
    "\n",
    "# Conditional logic to assign top-level keys\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "# optimization algorithm\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials\n",
    "\n",
    "# Keep track of results\n",
    "bayes_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# File to save first results\n",
    "out_file = 'results/gbm_trials.csv'\n",
    "of_connection = open(out_file, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write the headers to the file\n",
    "writer.writerow(['loss', 'params', 'iteration', 'estimators', 'train_time'])\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = MAX_EVALS, trials = bayes_trials, rstate = np.random.RandomState(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "bayes_trials_results = sorted(bayes_trials.results, key = lambda x: x['loss'])\n",
    "bayes_trials_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('results/gbm_trials.csv')\n",
    "\n",
    "# Sort with best scores on top and reset index for slicing\n",
    "results.sort_values('loss', ascending = True, inplace = True)\n",
    "results.reset_index(inplace = True, drop = True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convert from a string to a dictionary\n",
    "ast.literal_eval(results.loc[0, 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ideal number of estimators and hyperparameters\n",
    "best_bayes_estimators = int(results.loc[0, 'estimators'])\n",
    "best_bayes_params = ast.literal_eval(results.loc[0, 'params']).copy()\n",
    "\n",
    "# Re-create the best model and train on the training data\n",
    "best_bayes_model = lgb.LGBMClassifier(n_estimators=best_bayes_estimators, n_jobs = -1, \n",
    "                                       objective = 'binary', random_state = 50, **best_bayes_params)\n",
    "best_bayes_model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the testing data \n",
    "preds = best_bayes_model.predict_proba(test_features)[:, 1]\n",
    "print('The best model from Bayes optimization scores {:.5f} AUC ROC on the test set.'.format(roc_auc_score(test_labels, preds)))\n",
    "print('This was achieved after {} search iterations'.format(results.loc[0, 'iteration']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining quick use functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a quick function to find occurances of the target variable\n",
    "def find_target(df):\n",
    "    has_target = df['Target']==1\n",
    "    df_w_target = df[has_target]\n",
    "    return df_w_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function which sorts and filters and ranks the strongest relationships\n",
    "def rel_str(df):\n",
    "    pps_matrix = df.abs()\n",
    "    rel_str = (pps_matrix.where(np.triu(np.ones(df.shape), k=1).astype(np.bool))\n",
    "                 .stack()\n",
    "                 .sort_values(ascending=False))\n",
    "    print(\"The medium/strong relationships are:\", '\\n', rel_str[rel_str>0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating PPS heatmap chart\n",
    "def heatmap(df):\n",
    "    plt.figure(figsize=(75,75))\n",
    "    ax = sns.heatmap(df, vmin=0, vmax=1, cmap='coolwarm', linewidths=0.5, annot=True)\n",
    "    ax.set_title('PPS matrix')\n",
    "    ax.set_xlabel('feature')\n",
    "    ax.set_ylabel('target')\n",
    "    return ax, rel_str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Corr heatmap chart\n",
    "def corr_heatmap(df):\n",
    "    plt.figure(figsize=(75,75))\n",
    "    ax = sns.heatmap(df, vmin=-1, vmax=1, cmap=\"BrBG\", linewidths=0.5, annot=True)\n",
    "    ax.set_title('Correlation matrix')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing what other variables of those who with insurance policies have in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SweetViz for visualizing the overall data to determine where to further investigate\n",
    "#You will need to have a full screen to see whats on the right side.\n",
    "import sweetviz as sv\n",
    "#config reports\n",
    "#Configuring the reports, early attempts automatically catagorized MOSTYPE and PWAPART as numberical rather than categorical\n",
    "cfg_1 = sv.FeatureConfig(force_cat=['subtype_L0'])\n",
    "cfg_2 = sv.FeatureConfig(force_cat=['Contri_prv_3p_insur_L4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing all data to each other and the target variable\n",
    "report_combined = sv.analyze([find_target(post_enc_df), \"Combined\"], target_feat = \"Target\")\n",
    "report_combined.show_html(\"Report_Combined.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination of functions above:\n",
    "\n",
    "I used the \"find_target\" function to quickly find which variables were directly associated with our Target variable \"CARAVAN\".\n",
    "\n",
    "The report that is created shows the dtypes, correlations and associations, histograms of how the data distributes, and which features provide information on others. Only keeping the rows where CARAVAN = 1, we can see patterns begin to appear. For example, Contri_Lorry_pol gives no information on our target variable and can be dropped from the larger dataset to see how it effects the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPS Matrix Heatmaps\n",
    "\n",
    "Below are PPS matrix Heatmaps. A PPS matrix measures the predictive probability of one feature against  another feature. Due to the size of the dataset I wanted to use this to better understand the inner relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppscore as pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the PPS matrix of Socio-economic Demographics with Target Variable CARAVAN\n",
    "df_matrix_soec = pps.matrix(df_td.iloc[:, 0:43])\n",
    "\n",
    "# PPS Matrix heatmap for Socio-economic Demographics\n",
    "heatmap(df_matrix_soec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_heatmap(find_target(post_enc_so_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating PPS matrix for Policy Ownership data including the target variable\n",
    "df_matrix_own = pps.matrix(post_enc_own_df)\n",
    "\n",
    "#Heatmap of PPS Policy Ownership data\n",
    "heatmap(df_matrix_own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Applying to entire dataset\n",
    "df_matrix_td = pps.matrix(post_enc_df)\n",
    "\n",
    "#PPS matrix heatmap\n",
    "heatmap(df_matrix_td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have a rough idea on how everything relates, time to start dropping column features and narrowing down the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First I am going ot drop columns that have a mean of 0 found in the find_target function.\n",
    "#These are the columns that simply provide no information on the target variable\n",
    "cols = x.columns\n",
    "new_df = find_target(post_enc_df).drop(cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighborsClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_comp(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there are so many different features still, I will further limit the number of features by finding those\n",
    "# with a mean less that .05 and then dropping them. This will target the Policy Ownership group since they are binary.\n",
    "find_target(post_enc_df).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "cols = ['Contri_lorry_pol','romcath_L3_7', 'romcath_L3_8', 'romcath_L3_9', 'maintype_L2_4','subtype_L0_40','subtype_L0_28',\n",
    "                 'subtype_L0_21', 'subtype_L0_19','subtype_L0_18','subtype_L0_17', 'subtype_L0_16','subtype_L0_15','Num_ag_machines_pol',\n",
    "                 'Num_lorry_pol','Contri_ag_machine_pol']\n",
    "\n",
    "updated_df =  new_df.drop(cols, axis=1) #df_td.drop('Target', axis=1)# train_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_model_comp(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = updated_df.drop('Target', axis =1)\n",
    "y = updated_df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First split the data and create upsampled data set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Create training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# Performing standardization before applying PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "              'min_samples_split':[2,3,4,5],\n",
    "              'criterion' : ['gini','entropy']}\n",
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_obj = GridSearchCV(DecisionTreeClassifier(), parameters, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_fit = grid_obj.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = grid_fit.best_estimator_\n",
    "best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliced the data into its main features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PCA to find components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train)\n",
    "\n",
    "PCA(copy=True, iterated_power='auto', n_components=92, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It will give eigen values\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "X_train_pca = pca.transform(X_train)\n",
    "print(\"original shape:   \", X_train.shape)\n",
    "print(\"transformed shape:\", X_train_pca.shape)\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"original shape:   \", X_test.shape)\n",
    "print(\"transformed shape:\", X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') \n",
    "plt.title('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_n = range(pca.n_components_)\n",
    "pd.DataFrame(pca.components_, columns=x.columns, index=['pc_1', 'pc_2', 'pc_3','pc_4','pc_5','pc_6','pc_7','pc_8','pc_9','pc_10','pc_11','pc_12','pc_13','pc_14',\n",
    "                         'pc_15','pc_16','pc_17','pc_18','pc_19','pc_20','pc_21','pc_22','pc_23','pc_24','pc_25','pc_26','pc_27','pc_28',\n",
    "                         'pc_29','pc_30','pc_31','pc_32','pc_33','pc_34','pc_35','pc_36','pc_37','pc_38','pc_39','pc_40','pc_41','pc_42','pc_43','pc_44','pc_45','pc_46', 'pc_47', 'pc_48','pc_49','pc_50','pc_51','pc_52','pc_53','pc_54','pc_55','pc_56','pc_57','pc_58','pc_59','pc_60','pc_61','pc_62','pc_63','pc_64','pc_65','pc_66','pc_67','pc_68','pc_69','pc_70','pc_71','pc_72','pc_73','pc_74','pc_75','pc_76','pc_77','pc_78','pc_79','pc_80','pc_81','pc_82','pc_83','pc_84','pc_85','pc_86','pc_87','pc_88','pc_89','pc_90'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[25,25])\n",
    "plt.bar(features_n, pca.explained_variance_ratio_)\n",
    "plt.xlabel('PCA feature')\n",
    "plt.ylabel('variance')\n",
    "plt.xticks(features_n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "baseline = DummyClassifier(random_state=0).fit(X_train_pca, y_train)\n",
    "y_pred = baseline.predict(X_test_pca)\n",
    "print(round(accuracy_score(y_test, y_pred),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imbalance issue. Will adjust by Oversampling minority class and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "no_policy = post_enc_df[post_enc_df.CARAVAN==0][:348]\n",
    "has_policy = post_enc_df[post_enc_df.CARAVAN==1]\n",
    "\n",
    "# upsample minority\n",
    "has_pol_upsampled = resample(has_policy,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(no_policy), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([no_policy, has_pol_upsampled])\n",
    "\n",
    "new_df = upsampled.sample(frac=1, random_state=42)\n",
    "\n",
    "# check new class counts\n",
    "new_df.CARAVAN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_up = new_df.CARAVAN\n",
    "x_train_up = new_df.drop('CARAVAN', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_up.shape, y_train_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_up, X_test_up, y_train_up, y_test_up = train_test_split(x_train_up, y_train_up, test_size=0.2, random_state = 42)\n",
    "\n",
    "# Performing standardization before applying PCA\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_up)\n",
    "X_train = scaler.transform(X_train_up)\n",
    "print(X_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.95)\n",
    "pca.fit(X_train_up)\n",
    "\n",
    "PCA(copy=True, iterated_power='auto', n_components=153, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "baseline = DummyClassifier(random_state=0).fit(X_train_up, y_train_up)\n",
    "y_pred = baseline.predict(X_test)\n",
    "print(round(accuracy_score(y_test, y_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Below is the regular sampled data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is the oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
    "\n",
    "# Entire DataFrame\n",
    "corr = post_enc_df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\n",
    "ax1.set_title(\"Imbalanced Correlation Matrix \\n (don't use for reference)\", fontsize=14)\n",
    "\n",
    "\n",
    "sub_sample_corr = new_df.corr()\n",
    "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\n",
    "ax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n",
    "sns.boxplot(x=\"Class\", y=\"V17\", data=new_df, palette=colors, ax=axes[0])\n",
    "axes[0].set_title('V17 vs Class Negative Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df, palette=colors, ax=axes[1])\n",
    "axes[1].set_title('V14 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, palette=colors, ax=axes[2])\n",
    "axes[2].set_title('V12 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, palette=colors, ax=axes[3])\n",
    "axes[3].set_title('V10 vs Class Negative Correlation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find importance of features in top 3 systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "model_gbc = gbc.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_gbc = pd.DataFrame(gbc.feature_importances_,\n",
    "                                   index = X_train_up.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_gbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "model_rfc = rfc.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_rfc = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_train_up.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20), n_estimators=200)\n",
    "model_abc = abc.fit(X_train_up, y_train_up)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_abc = pd.DataFrame(abc.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-SNE Implementation\n",
    "t0 = time.time()\n",
    "X_train_reduced_tsne = TSNE(n_components=3, random_state=42).fit_transform(x.values)\n",
    "t1 = time.time()\n",
    "print(\"T-SNE took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# PCA Implementation\n",
    "t0 = time.time()\n",
    "X_train_reduced_pca = PCA(n_components=3, random_state=42).fit_transform(x.values)\n",
    "t1 = time.time()\n",
    "print(\"PCA took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# TruncatedSVD\n",
    "t0 = time.time()\n",
    "X_train_reduced_svd = TruncatedSVD(n_components=3, algorithm='randomized', random_state=42).fit_transform(x.values)\n",
    "t1 = time.time()\n",
    "print(\"Truncated SVD took {:.2} s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,6))\n",
    "# labels = ['No policy', 'Policy']\n",
    "f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n",
    "\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Policy')\n",
    "red_patch = mpatches.Patch(color='#AF0000', label='Policy')\n",
    "\n",
    "\n",
    "# t-SNE scatter plot\n",
    "ax1.scatter(X_train_reduced_tsne[:,0], X_train_reduced_tsne[:,1], c=(y == 0), cmap='coolwarm', label='No Policy', linewidths=2)\n",
    "ax1.scatter(X_train_reduced_tsne[:,0], X_train_reduced_tsne[:,1], c=(y == 1), cmap='coolwarm', label='Policy', linewidths=2)\n",
    "ax1.set_title('t-SNE', fontsize=14)\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "ax1.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "\n",
    "# PCA scatter plot\n",
    "ax2.scatter(X_train_reduced_pca[:,0], X_train_reduced_pca[:,1], c=(y == 0), cmap='coolwarm', label='No Policy', linewidths=2)\n",
    "ax2.scatter(X_train_reduced_pca[:,0], X_train_reduced_pca[:,1], c=(y == 1), cmap='coolwarm', label='Policy', linewidths=2)\n",
    "ax2.set_title('PCA', fontsize=14)\n",
    "\n",
    "ax2.grid(True)\n",
    "\n",
    "ax2.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "# TruncatedSVD scatter plot\n",
    "ax3.scatter(X_train_reduced_svd[:,0], X_train_reduced_svd[:,1], c=(y == 0), cmap='coolwarm', label='No Policy', linewidths=2)\n",
    "ax3.scatter(X_train_reduced_svd[:,0], X_train_reduced_svd[:,1], c=(y == 1), cmap='coolwarm', label='Policy', linewidths=2)\n",
    "ax3.set_title('Truncated SVD', fontsize=14)\n",
    "\n",
    "ax3.grid(True)\n",
    "\n",
    "ax3.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
