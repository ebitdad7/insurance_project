{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_td = pd.read_csv('tic_2000_train_data.csv')\n",
    "eval1 = pd.read_csv('tic_2000_eval_data.csv')\n",
    "target = pd.read_csv('tic_2000_target_data.csv') #CARAVAN is renamed 'Target' in this set\n",
    "\n",
    "#renaming the training data to match the test data.\n",
    "df_td.rename(columns={'CARAVAN': 'Target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":FEATURES DONE:                    |█████████████████████| [100%]   00:14  -> (00:00 left)\n",
      ":PAIRWISE DONE:                    |█████████████████████| [100%]   00:26  -> (00:00 left)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Associations graph... DONE!\n"
     ]
    }
   ],
   "source": [
    "# Using SweetViz for visualizing the overall data to determine where to further investigate\n",
    "#You will need to have a full screen to see whats on the right side.\n",
    "import sweetviz as sv\n",
    "#config reports\n",
    "#Configuring the reports, early attempts automatically catagorized MOSTYPE and PWAPART as numberical rather than categorical\n",
    "cfg_1 = sv.FeatureConfig(force_cat=['MOSTYPE'])\n",
    "\n",
    "report_combined = sv.analyze([df_td, \"Combined\"], target_feat = \"Target\", feat_cfg=cfg_1)\n",
    "report_combined.show_html(\"Report_Combined.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Thoughts on Data Above:\n",
    "According to the Insurance challange the data is split into 2 sections: Demographics 0-42 and Policy ownership 43-86.The latter includes our target. Additionally, the features are based on the zipcodes which is unknown.\n",
    "    Note: you can hover over areas of the report or click the different tabs and that will pull up the bar charts and associations.\n",
    "\n",
    "\n",
    "#### 1) The target variable is heavily imbalanced.\n",
    "With only 348 instances of there being a Caravan policy; this will need to be addressed in order to prevent overfitting. I will undersample the instances which there is no Caravan policy and use ComplementNB to solve this issue.\n",
    "\n",
    "#### 2) There are 14 features that give information on our target variable and provide a good starting point for investigation.\n",
    "These features are:\n",
    "PPERSAUT, PBRAND, APERSAUT, MOSTYPE, MOSHOOFD, MINKGEM, MKOOPKLA, MINKM30, MOPLLAAG, PWAPART, MAUT0, AWAPART, MHHUUR, MHKOOP\n",
    "\n",
    "    note: Sweetviz uses the uncertain coefficient to measure relationships of catagorical data.\n",
    "\n",
    "#### 3) It becomes immediately evident there is a lot of noise made up the sub-catagories in the data.\n",
    "Given that the dataset is filled with subcategories, I will create dummy tables to assist in feature selection and see if the above features in their subcategories are still present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":FEATURES DONE:                    |█████████████████████| [100%]   00:02  -> (00:00 left)\n",
      ":PAIRWISE DONE:                    |█████████████████████| [100%]   00:00  -> (00:00 left)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Associations graph... DONE!\n"
     ]
    }
   ],
   "source": [
    "#I am going to start off exploring the 14 features the report originally highlights\n",
    "modified_df = df_td[['PPERSAUT', 'PBRAND', 'APERSAUT', 'MOSTYPE', 'MOSHOOFD', 'MINKGEM',\n",
    "                     'MKOOPKLA', 'MINKM30', 'MOPLLAAG', 'PWAPART', 'MAUT0', 'AWAPART', 'MHHUUR', 'MHKOOP', 'Target']]\n",
    "\n",
    "modified_df_report = sv.analyze([modified_df, \"Combined\"], target_feat = \"Target\", feat_cfg=cfg_1)\n",
    "modified_df_report.show_html(\"Mod_Report_Combined.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at this report, we can get a good sense as to which features in particular have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy tables and leaving our Target variable \"Caravan\" out for models.\n",
    "pre_enc= df_td.drop('Target', axis=1)\n",
    "post_enc_df = pd.get_dummies(df_td, prefix_sep=\"_\", columns=pre_enc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select features I will be using LassoCV and see if I get a similar batch as to what appeared in the\n",
    "#... earlier report.\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "X = post_enc_df.drop('Target', axis=1)\n",
    "y = post_enc_df.Target\n",
    "reg = LassoCV(max_iter=100000, tol=0.00001)\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" % reg.score(X, y))\n",
    "coef = pd.Series(reg.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0))+ \" variables\")\n",
    "\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (10, 100)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None) \n",
    "kept_labels = imp_coef[imp_coef != 0]\n",
    "kept_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_labels.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a reminder of what was in the initial report, these were the features that gave information on our target variable:\n",
    "PPERSAUT, PBRAND, APERSAUT, MOSTYPE, MOSHOOFD, MINKGEM, MKOOPKLA, MINKM30, MOPLLAAG, PWAPART, MAUT0, AWAPART, MHHUUR, MHKOOP\n",
    "\n",
    "#### Comparing the two lists, we picked up some new features and were able to narrow down to certain subfeatures.\n",
    "To better explain our results this will require a bit of intuition about customer demographics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using LassoCV, we now have our new features\n",
    "new_df = post_enc_df[['PPLEZIER_0', 'MINKGEM_3', 'MGODOV_1', 'PBRAND_2', 'MOPLHOOG_0',\n",
    "       'ALEVEN_1', 'MZFONDS_6', 'MINK7512_0', 'MAUT0_4', 'MSKC_5',\n",
    "       'MBERHOOG_5', 'MOSHOOFD_10', 'MGODGE_6', 'MSKB1_2', 'MSKA_2', 'MSKD_3',\n",
    "       'MINK3045_5', 'MHKOOP_7', 'MAUT1_4', 'MOPLHOOG_3', 'MBERMIDD_3',\n",
    "       'AFIETS_0', 'MOPLHOOG_2', 'MBERZELF_0', 'MFGEKIND_5', 'MFWEKIND_5',\n",
    "       'PFIETS_0', 'APLEZIER_0', 'MZPART_2', 'MOPLHOOG_1', 'MHKOOP_9',\n",
    "       'MGODOV_2', 'MRELGE_9', 'MSKD_0', 'MAUT2_1', 'MAUT0_2', 'MFGEKIND_4',\n",
    "       'MOPLLAAG_2', 'MOSHOOFD_1', 'MZFONDS_7', 'MBERARBG_2', 'MINKGEM_5',\n",
    "       'MOSTYPE_3', 'MSKC_1', 'MSKD_1', 'MINKGEM_4', 'MOSHOOFD_9', 'MRELSA_0',\n",
    "       'MRELOV_3', 'MINK123M_0', 'MOSTYPE_8', 'MINK7512_1', 'MGODRK_1',\n",
    "       'MOSHOOFD_2', 'ABYSTAND_1', 'PWAPART_2', 'MAUT1_7', 'MBERBOER_0',\n",
    "       'MHHUUR_0', 'MBERARBG_1', 'MINKM30_2', 'MGODPR_7', 'PBRAND_3',\n",
    "       'APERSAUT_2', 'MKOOPKLA_7', 'PBRAND_4', 'PPERSAUT_6','Target']]\n",
    "\n",
    "new_report = sv.analyze([new_df, \"Combined\"], target_feat = \"Target\")\n",
    "new_report.show_html(\"New_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, plot_roc_curve, classification_report, balanced_accuracy_score, coverage_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def clf_comp(df):\n",
    "    classifiers = [\n",
    "    ComplementNB(),\n",
    "    MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    RandomForestClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    GaussianProcessClassifier()\n",
    "    ]\n",
    "    \n",
    "    # Separating out the features\n",
    "    X =  df.drop('Target', axis=1) #df_td.drop('Target', axis=1)# train_feat\n",
    "    # Separating out the target\n",
    "    y = df.Target #df_td.Target#target_feat\n",
    "    \n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "    for classifier in classifiers:\n",
    "        scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "        model = classifier.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        print(classifier)\n",
    "        print('The Training F1 Score is', f1_score(classifier.predict(X_train), y_train))\n",
    "        print('The Testing F1 Score is', f1_score(predictions, y_test))\n",
    "        print(\"accuracy score\" '\\n', accuracy_score(y_test, predictions))\n",
    "        print(\"balanced_accuracy_score\" '\\n', balanced_accuracy_score(y_test, predictions))\n",
    "        print(\"model confusion matrix\" '\\n', confusion_matrix(y_test, predictions, normalize='all'))\n",
    "        print(\"classification_report\" '\\n', classification_report(y_test, predictions),'\\n')\n",
    "        ax = plt.gca()\n",
    "        plt.rcParams['figure.figsize'] = (10, 10)\n",
    "        disp = plot_roc_curve(classifier, X_test,y_test, ax=ax, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_comp(post_enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
