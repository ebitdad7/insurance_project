{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ppscore as pps\n",
    "import statsmodels as sm\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, random_forest, gaussian_nb, gradient_boosting\n",
    "from hyperopt import tpe\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target feature in Training Data; Balance \n",
      " 0    5474\n",
      "1     348\n",
      "Name: CARAVAN, dtype: int64\n",
      "Target feature in Target Data; Balance \n",
      " 0    3762\n",
      "1     238\n",
      "Name: Target, dtype: int64\n",
      "Training Features Dataset; Shape (5822, 86)\n",
      "Eval Features Dataset; Shape (4000, 85)\n",
      "Target Feature Dataset; Shape (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_td = pd.read_csv('tic_2000_train_data.csv')\n",
    "eval1 = pd.read_csv('tic_2000_eval_data.csv')\n",
    "target = pd.read_csv('tic_2000_target_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "#First looking at the data, it is evident there is a definate imbalnace in the target variable\n",
    "#Due to the heavy imbalance, I will first try to isolate the features that are directly related to the target\n",
    "# variable, and then unbalance the data set and use a backwards elimination process to further trim down the features.\n",
    "print('Target feature in Training Data; Balance', '\\n',df_td.CARAVAN.value_counts())\n",
    "print('Target feature in Target Data; Balance', '\\n',target.Target.value_counts())\n",
    "#No missing values, and all equal head counts.\n",
    "print('Training Features Dataset; Shape', df_td.shape)\n",
    "print('Eval Features Dataset; Shape', eval1.shape)\n",
    "print('Target Feature Dataset; Shape', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming variables to easy reading\n",
    "df_td.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur_L4','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol', 'CARAVAN' : 'Target'},\n",
    "          inplace=True)\n",
    "\n",
    "eval1.rename(columns={'MOSTYPE': 'subtype_L0', 'MAANTHUI':'Num_houses', 'MGEMOMV' : 'Avg_hh_size',\n",
    "                   'MGEMLEEF':'age_L1', 'MOSHOOFD': 'maintype_L2', 'MGODRK': 'romcath_L3',\n",
    "                   'MGODPR': 'Protestant','MGODOV' : 'O_religion', 'MGODGE': 'N_religion','MRELGE' :'Married',\n",
    "                   'MRELSA' : 'Living_together','MRELOV' : 'O_relation','MFALLEEN' : 'Singles','MFGEKIND' : 'hh_wo_child',\n",
    "                   'MFWEKIND' : 'hh_w_child','MOPLHOOG' : 'H_lvl_edu','MOPLMIDD' : 'M_lvl_edu',\n",
    "                   'MOPLLAAG' : 'L_lvl_edu','MBERHOOG' : 'H_status','MBERZELF' : 'Entrepreneur','MBERBOER' : 'Farmer',\n",
    "                   'MBERMIDD' : 'Mid_management','MBERARBG' : 'Skld_labor','MBERARBO' : 'Unskld_labor',\n",
    "                   'MSKA' : 'Soc_cls_A','MSKB1' : 'Soc_cls_B1','MSKB2' : 'Soc_cls_B2','MSKC' : 'Soc_cls_C',\n",
    "                   'MSKD' : 'Soc_cls_D','MHHUUR' : 'R_house','MHKOOP' : 'O_house','MAUT1' : '1_car','MAUT2' : '2_cars',\n",
    "                   'MAUT0' : 'N_car','MZFONDS' : 'Nat_Hlth_Serv','MZPART' : 'Prv_Hlth_Insur','MINKM30' : 'Inc_u_30k',\n",
    "                   'MINK3045' : 'Inc_btw_30_45k','MINK4575' : 'Inc_btw_45_75k','MINK7512' : 'Inc_75_122k','MINK123M' : 'Inc_ovr_123k',\n",
    "                   'MINKGEM' : 'Avg_inc','MKOOPKLA' : 'PP_cls','PWAPART' : 'Contri_prv_3p_insur_L4','PWABEDR' : 'Firm_Contri_3p_ insur',\n",
    "                   'PWALAND' : 'Ag_Contri_3p_insur','PPERSAUT' : 'Contri_car_pol','PBESAUT' : 'Contri_deliv_van_pol',\n",
    "                   'PMOTSCO' : 'Contri_motorcycle/scooter_pol','PVRAAUT' : 'Contri_lorry_pol','PAANHANG' : 'Contri_trailer_pols',\n",
    "                   'PTRACTOR' : 'Contri_tractor_pol','PWERKT' : 'Contri_ag_machine_pol','PBROM' : 'Contri_moped_pol',\n",
    "                   'PLEVEN' : 'Contri_life_insur','PPERSONG' : 'Contri_prv_accid_insur_pol',\n",
    "                   'PGEZONG' : 'Contri_fam_accid_insur_pol','PWAOREG' : 'Contri_disabl_insur_pol','PBRAND' : 'Contri_fire_pol',\n",
    "                   'PZEILPL' : 'Contri_surfb_pol','PPLEZIER' : 'Contri_boat_pol','PFIETS' : 'Contri_bike_pol',\n",
    "                   'PINBOED' : 'Contri_prop_insur_pol','PBYSTAND' : 'Contri_ss_insur_polo','AWAPART' : 'Num_prv_3p_insur',\n",
    "                   'AWABEDR' : 'Num_firm_3p_insur','AWALAND' : 'Num_ag_3p_insur','APERSAUT' : 'Num_car_pol',\n",
    "                   'ABESAUT' : 'Num_deliv_van_pol','AMOTSCO' : 'Num_motorcycle/scooter_pol', 'AVRAAUT' : 'Num_lorry_pol','AAANHANG': 'Num_trailer_pol',\n",
    "                   'ATRACTOR' : 'Num_tractor_pol','AWERKT' : 'Num_ag_machines_pol','ABROM' : 'Num_moped_pol',\n",
    "                   'ALEVEN' : 'Num_life_insur_pol', 'APERSONG' : 'Num_prv_accid_insur_pol','AGEZONG' : 'Num_fam_ccid_insur_pol',\n",
    "                   'AWAOREG' : 'Num_disabl_insur_pol','ABRAND' :'Num_fire_pol','AZEILPL' :'Num_surfb_pol','APLEZIER' :'Num_boat_pol',\n",
    "                   'AFIETS' :'Num_bike_pol','AINBOED' :'Num_prop_insur_pol','ABYSTAND' :'num_ss_insur_pol'},\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_enc= ['subtype_L0', 'age_L1', 'maintype_L2']\n",
    "post_enc_df = pd.get_dummies(df_td, prefix_sep=\"_\", columns=pre_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = post_enc_df['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set() # Set of all the names of deleted columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i] # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname] # deleting the column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = post_enc_df.drop('Target', axis=1)\n",
    "y = post_enc_df.Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "\n",
    "reg = LassoCV(max_iter = 10000, tol=0.00001)\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoCV().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 30)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original dataset getting dummies.\n",
    "print(coef[coef != 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_col = post_enc_df[['romcath_L3','Protestant','O_religion','N_religion','Married','Living_together','H_lvl_edu','L_lvl_edu','Farmer','Mid_management',\n",
    "                        'Skld_labor','Soc_cls_B1','Soc_cls_C','R_house','1_car','Prv_Hlth_Insur','Inc_btw_30_45k','Inc_75_122k',\n",
    "                       'Inc_ovr_123k','Avg_inc','PP_cls','Contri_prv_3p_insur_L4','Ag_Contri_3p_insur','Ag_Contri_3p_insur','Contri_car_pol',          \n",
    "                'Contri_tractor_pol','Contri_disabl_insur_pol','Contri_fire_pol','Contri_boat_pol','Contri_ss_insur_polo',\n",
    "                       'subtype_L0_8', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = lasso_col.drop('Target', axis=1)\n",
    "y = lasso_col.Target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)  \n",
    "\n",
    "# Instantiate a HyperoptEstimator with the search space and number of evaluations\n",
    "\n",
    "estim = HyperoptEstimator(classifier=gradient_boosting('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix, plot_roc_curve, classification_report, balanced_accuracy_score, coverage_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.030509817593472984,\n",
    "                           loss='exponential', max_features=0.36684107529168053,\n",
    "                           min_samples_leaf=8, n_estimators=287, presort='auto',\n",
    "                           random_state=3)\n",
    "\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "print(\"accuracy score\" '\\n', accuracy_score(y_test, predictions))\n",
    "print(\"model confusion matrix\" '\\n', confusion_matrix(y_test, predictions, normalize='all'))\n",
    "print(\"classification_report\" '\\n', classification_report(y_test, predictions),'\\n')\n",
    "ax = plt.gca()\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "disp = plot_roc_curve(classifier, X_test, y_test, ax=ax, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_rf = HyperoptEstimator(classifier=random_forest('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_rf.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_rf.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_rf.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_gbt = HyperoptEstimator(classifier=gradient_boosting('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_gbt.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_gbt.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_gbt.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_guas = HyperoptEstimator(classifier=gaussian_nb('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_guas.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_guas.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_guas.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_find = HyperoptEstimator( algo=tpe.suggest, \n",
    "                            max_evals=150, \n",
    "                            trial_timeout=60 )\n",
    "\n",
    "estim_find.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "# 1.0\n",
    "\n",
    "print( estim_find.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import extra_trees\n",
    "\n",
    "estim_et = HyperoptEstimator(classifier=extra_trees('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_et.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_et.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_et.best_model() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpsklearn import knn, decision_tree, ada_boost, linear_discriminant_analysis, quadratic_discriminant_analysis, xgboost_classification\n",
    "\n",
    "estim_knn = HyperoptEstimator(classifier=knn('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_knn.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_knn.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_knn.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_dt = HyperoptEstimator(classifier=decision_tree('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_dt.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_dt.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_dt.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_adab = HyperoptEstimator(classifier=ada_boost('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_adab.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_adab.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_adab.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_lda = HyperoptEstimator(classifier=linear_discriminant_analysis('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_lda.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_lda.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_lda.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_qda = HyperoptEstimator(classifier=quadratic_discriminant_analysis('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_qda.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_qda.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_qda.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_xgb = HyperoptEstimator(classifier=xgboost_classification('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim_xgb.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print( estim_xgb.best_model() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
